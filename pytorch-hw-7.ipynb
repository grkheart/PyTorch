{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e8fb376",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-02-15T08:19:51.964053Z",
     "iopub.status.busy": "2023-02-15T08:19:51.963579Z",
     "iopub.status.idle": "2023-02-15T08:19:51.998425Z",
     "shell.execute_reply": "2023-02-15T08:19:51.997478Z"
    },
    "papermill": {
     "duration": 0.049834,
     "end_time": "2023-02-15T08:19:52.001278",
     "exception": false,
     "start_time": "2023-02-15T08:19:51.951444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/twitter-sentiment-analysis-hatred-speech/train.csv\n",
      "/kaggle/input/twitter-sentiment-analysis-hatred-speech/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0a9aa2",
   "metadata": {
    "papermill": {
     "duration": 0.007129,
     "end_time": "2023-02-15T08:19:52.016170",
     "exception": false,
     "start_time": "2023-02-15T08:19:52.009041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Домашнее задани:\n",
    "\n",
    "Попробуйте обучить нейронную сеть GRU/LSTM для предсказания сентимента сообщений с твитера на примере https://www.kaggle.com/datasets/arkhoshghalb/twitter-sentiment-analysis-hatred-speech\n",
    "\n",
    "Опишите, какой результат вы получили? Что помогло вам улучшить ее точность?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fb1ece",
   "metadata": {
    "papermill": {
     "duration": 0.006313,
     "end_time": "2023-02-15T08:19:52.028792",
     "exception": false,
     "start_time": "2023-02-15T08:19:52.022479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd5fedaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:19:52.044114Z",
     "iopub.status.busy": "2023-02-15T08:19:52.042707Z",
     "iopub.status.idle": "2023-02-15T08:20:03.459582Z",
     "shell.execute_reply": "2023-02-15T08:20:03.458304Z"
    },
    "papermill": {
     "duration": 11.426573,
     "end_time": "2023-02-15T08:20:03.462055",
     "exception": false,
     "start_time": "2023-02-15T08:19:52.035482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "Requirement already satisfied: conda in /opt/conda/lib/python3.7/site-packages (4.14.0)\r\n",
      "Requirement already satisfied: pycosat>=0.6.3 in /opt/conda/lib/python3.7/site-packages (from conda) (0.6.3)\r\n",
      "Requirement already satisfied: requests>=2.20.1 in /opt/conda/lib/python3.7/site-packages (from conda) (2.28.1)\r\n",
      "Requirement already satisfied: ruamel_yaml_conda>=0.11.14 in /opt/conda/lib/python3.7/site-packages (from conda) (0.15.100)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.1->conda) (1.26.11)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.1->conda) (2.1.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.1->conda) (2022.12.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.1->conda) (3.3)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a430af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:03.477888Z",
     "iopub.status.busy": "2023-02-15T08:20:03.477549Z",
     "iopub.status.idle": "2023-02-15T08:20:12.972930Z",
     "shell.execute_reply": "2023-02-15T08:20:12.971495Z"
    },
    "papermill": {
     "duration": 9.506021,
     "end_time": "2023-02-15T08:20:12.975379",
     "exception": false,
     "start_time": "2023-02-15T08:20:03.469358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.7/site-packages (0.11.1)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (23.0)\r\n",
      "Requirement already satisfied: torch>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (1.12.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (4.1.1)\r\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (1.21.6)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb9a5683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:12.991770Z",
     "iopub.status.busy": "2023-02-15T08:20:12.991395Z",
     "iopub.status.idle": "2023-02-15T08:20:24.555541Z",
     "shell.execute_reply": "2023-02-15T08:20:24.554116Z"
    },
    "papermill": {
     "duration": 11.575842,
     "end_time": "2023-02-15T08:20:24.558732",
     "exception": false,
     "start_time": "2023-02-15T08:20:12.982890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "Collecting pymorphy2\r\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m634.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting pymorphy2-dicts-ru<3.0,>=2.4\r\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /opt/conda/lib/python3.7/site-packages (from pymorphy2) (0.6.2)\r\n",
      "Collecting dawg-python>=0.7.1\r\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\r\n",
      "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\r\n",
      "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac07607a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:24.597560Z",
     "iopub.status.busy": "2023-02-15T08:20:24.597112Z",
     "iopub.status.idle": "2023-02-15T08:20:30.812359Z",
     "shell.execute_reply": "2023-02-15T08:20:30.811190Z"
    },
    "papermill": {
     "duration": 6.238575,
     "end_time": "2023-02-15T08:20:30.814859",
     "exception": false,
     "start_time": "2023-02-15T08:20:24.576284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchmetrics\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b43d2a1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:30.832599Z",
     "iopub.status.busy": "2023-02-15T08:20:30.832289Z",
     "iopub.status.idle": "2023-02-15T08:20:30.967036Z",
     "shell.execute_reply": "2023-02-15T08:20:30.966150Z"
    },
    "papermill": {
     "duration": 0.146301,
     "end_time": "2023-02-15T08:20:30.969575",
     "exception": false,
     "start_time": "2023-02-15T08:20:30.823274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f34806cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:30.986769Z",
     "iopub.status.busy": "2023-02-15T08:20:30.986488Z",
     "iopub.status.idle": "2023-02-15T08:20:31.063266Z",
     "shell.execute_reply": "2023-02-15T08:20:31.062207Z"
    },
    "papermill": {
     "duration": 0.087911,
     "end_time": "2023-02-15T08:20:31.065353",
     "exception": false,
     "start_time": "2023-02-15T08:20:30.977442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fa88abb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:31.083349Z",
     "iopub.status.busy": "2023-02-15T08:20:31.082565Z",
     "iopub.status.idle": "2023-02-15T08:20:31.194113Z",
     "shell.execute_reply": "2023-02-15T08:20:31.192997Z"
    },
    "papermill": {
     "duration": 0.123056,
     "end_time": "2023-02-15T08:20:31.196547",
     "exception": false,
     "start_time": "2023-02-15T08:20:31.073491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1eb970",
   "metadata": {
    "papermill": {
     "duration": 0.008215,
     "end_time": "2023-02-15T08:20:31.213217",
     "exception": false,
     "start_time": "2023-02-15T08:20:31.205002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19978d57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:31.231397Z",
     "iopub.status.busy": "2023-02-15T08:20:31.230593Z",
     "iopub.status.idle": "2023-02-15T08:20:31.418028Z",
     "shell.execute_reply": "2023-02-15T08:20:31.416847Z"
    },
    "papermill": {
     "duration": 0.198942,
     "end_time": "2023-02-15T08:20:31.420465",
     "exception": false,
     "start_time": "2023-02-15T08:20:31.221523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/twitter-sentiment-analysis-hatred-speech/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/twitter-sentiment-analysis-hatred-speech/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e84866cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:31.439651Z",
     "iopub.status.busy": "2023-02-15T08:20:31.438813Z",
     "iopub.status.idle": "2023-02-15T08:20:31.454366Z",
     "shell.execute_reply": "2023-02-15T08:20:31.453389Z"
    },
    "papermill": {
     "duration": 0.027069,
     "end_time": "2023-02-15T08:20:31.456530",
     "exception": false,
     "start_time": "2023-02-15T08:20:31.429461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train, df_valid = train_test_split(train_df, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fd91ecf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:31.475256Z",
     "iopub.status.busy": "2023-02-15T08:20:31.474452Z",
     "iopub.status.idle": "2023-02-15T08:20:31.481873Z",
     "shell.execute_reply": "2023-02-15T08:20:31.480973Z"
    },
    "papermill": {
     "duration": 0.019047,
     "end_time": "2023-02-15T08:20:31.483969",
     "exception": false,
     "start_time": "2023-02-15T08:20:31.464922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sw = set(stopwords.words('english'))\n",
    "punct = set(punctuation)\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f3e095d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:31.501996Z",
     "iopub.status.busy": "2023-02-15T08:20:31.501234Z",
     "iopub.status.idle": "2023-02-15T08:20:31.506771Z",
     "shell.execute_reply": "2023-02-15T08:20:31.505832Z"
    },
    "papermill": {
     "duration": 0.016733,
     "end_time": "2023-02-15T08:20:31.508930",
     "exception": false,
     "start_time": "2023-02-15T08:20:31.492197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(txt):\n",
    "    #преобразуем входные данные в строку\n",
    "    txt = str(txt)\n",
    "    #удяляем знаки пунктуации\n",
    "    txt = \"\".join(c for c in txt if c not in punct)\n",
    "    #приводим все к нижнему регистру\n",
    "    txt = txt.lower()\n",
    "    #лематизация и удаление стоп-слов\n",
    "    txt = [lemmatizer.lemmatize(w) for w in txt.split() if w not in sw]\n",
    "    return \" \".join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42ef68cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:31.526956Z",
     "iopub.status.busy": "2023-02-15T08:20:31.526181Z",
     "iopub.status.idle": "2023-02-15T08:20:36.053491Z",
     "shell.execute_reply": "2023-02-15T08:20:36.052174Z"
    },
    "papermill": {
     "duration": 4.538559,
     "end_time": "2023-02-15T08:20:36.055827",
     "exception": false,
     "start_time": "2023-02-15T08:20:31.517268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23971/23971 [00:02<00:00, 7997.07it/s] \n",
      "100%|██████████| 7991/7991 [00:00<00:00, 19187.60it/s]\n",
      "100%|██████████| 17197/17197 [00:01<00:00, 15861.72it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "df_train['tweet'] = df_train['tweet'].progress_apply(preprocess_text)\n",
    "df_valid['tweet'] = df_valid['tweet'].progress_apply(preprocess_text)\n",
    "test_df['tweet'] = test_df['tweet'].progress_apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db62db29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:36.094787Z",
     "iopub.status.busy": "2023-02-15T08:20:36.094174Z",
     "iopub.status.idle": "2023-02-15T08:20:36.790768Z",
     "shell.execute_reply": "2023-02-15T08:20:36.789844Z"
    },
    "papermill": {
     "duration": 0.720439,
     "end_time": "2023-02-15T08:20:36.793165",
     "exception": false,
     "start_time": "2023-02-15T08:20:36.072726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['like',\n",
       " 'cant',\n",
       " 'please',\n",
       " 'hospital',\n",
       " 'recovering',\n",
       " 'inside',\n",
       " 'club',\n",
       " 'shane',\n",
       " 'pleeease',\n",
       " 'user']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus = \" \".join(df_train[\"tweet\"])\n",
    "train_corpus = train_corpus.lower()\n",
    "tokens = word_tokenize(train_corpus)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab01d093",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:36.816720Z",
     "iopub.status.busy": "2023-02-15T08:20:36.815279Z",
     "iopub.status.idle": "2023-02-15T08:20:36.844185Z",
     "shell.execute_reply": "2023-02-15T08:20:36.843325Z"
    },
    "papermill": {
     "duration": 0.042423,
     "end_time": "2023-02-15T08:20:36.846231",
     "exception": false,
     "start_time": "2023-02-15T08:20:36.803808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens_filtered = [word for word in tokens if word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "484b915a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:36.868712Z",
     "iopub.status.busy": "2023-02-15T08:20:36.867711Z",
     "iopub.status.idle": "2023-02-15T08:20:36.994552Z",
     "shell.execute_reply": "2023-02-15T08:20:36.993657Z"
    },
    "papermill": {
     "duration": 0.140108,
     "end_time": "2023-02-15T08:20:36.996699",
     "exception": false,
     "start_time": "2023-02-15T08:20:36.856591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dist = FreqDist(tokens_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4548a07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:37.019786Z",
     "iopub.status.busy": "2023-02-15T08:20:37.018269Z",
     "iopub.status.idle": "2023-02-15T08:20:37.024231Z",
     "shell.execute_reply": "2023-02-15T08:20:37.023340Z"
    },
    "papermill": {
     "duration": 0.019319,
     "end_time": "2023-02-15T08:20:37.026225",
     "exception": false,
     "start_time": "2023-02-15T08:20:37.006906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_words = 20000\n",
    "max_len = 10\n",
    "num_classes = 1\n",
    "\n",
    "# обучение\n",
    "epochs = 10\n",
    "batch_size = 512\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46a802f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:37.050182Z",
     "iopub.status.busy": "2023-02-15T08:20:37.048734Z",
     "iopub.status.idle": "2023-02-15T08:20:37.087074Z",
     "shell.execute_reply": "2023-02-15T08:20:37.086074Z"
    },
    "papermill": {
     "duration": 0.051998,
     "end_time": "2023-02-15T08:20:37.089431",
     "exception": false,
     "start_time": "2023-02-15T08:20:37.037433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19999,\n",
       " ['user', 'day', 'love', 'happy', 'u', 'amp', 'time', 'life', 'im', 'like'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]  # -1 - padding\n",
    "len(tokens_filtered_top), tokens_filtered_top[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "170b9745",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:37.111426Z",
     "iopub.status.busy": "2023-02-15T08:20:37.111114Z",
     "iopub.status.idle": "2023-02-15T08:20:37.119535Z",
     "shell.execute_reply": "2023-02-15T08:20:37.118470Z"
    },
    "papermill": {
     "duration": 0.02148,
     "end_time": "2023-02-15T08:20:37.121357",
     "exception": false,
     "start_time": "2023-02-15T08:20:37.099877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top,1)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5edf6652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:37.144200Z",
     "iopub.status.busy": "2023-02-15T08:20:37.143310Z",
     "iopub.status.idle": "2023-02-15T08:20:37.149749Z",
     "shell.execute_reply": "2023-02-15T08:20:37.148635Z"
    },
    "papermill": {
     "duration": 0.019613,
     "end_time": "2023-02-15T08:20:37.151842",
     "exception": false,
     "start_time": "2023-02-15T08:20:37.132229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())  #токенизация\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()] #фильтруем (только буквы и цифры)\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word]) #если слово в топе токенов, то добавляем его индекс в результат\n",
    "\n",
    "    padding = [0] * (maxlen-len(result)) #нули дополняющие до maxlen\n",
    "    return result[-maxlen:] + padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52ba0f54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:37.173381Z",
     "iopub.status.busy": "2023-02-15T08:20:37.173087Z",
     "iopub.status.idle": "2023-02-15T08:20:42.268047Z",
     "shell.execute_reply": "2023-02-15T08:20:42.267039Z"
    },
    "papermill": {
     "duration": 5.108433,
     "end_time": "2023-02-15T08:20:42.270456",
     "exception": false,
     "start_time": "2023-02-15T08:20:37.162023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23971, 10), (7991, 10), (17197, 10))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.asarray([text_to_sequence(text, max_len) for text in df_train[\"tweet\"]], dtype=np.int32)\n",
    "x_valid = np.asarray([text_to_sequence(text, max_len) for text in df_valid[\"tweet\"]], dtype=np.int32)\n",
    "x_test = np.asarray([text_to_sequence(text, max_len) for text in test_df[\"tweet\"]], dtype=np.int32)\n",
    "\n",
    "x_train.shape, x_valid.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a016af25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:42.293384Z",
     "iopub.status.busy": "2023-02-15T08:20:42.293081Z",
     "iopub.status.idle": "2023-02-15T08:20:42.299707Z",
     "shell.execute_reply": "2023-02-15T08:20:42.298639Z"
    },
    "papermill": {
     "duration": 0.019887,
     "end_time": "2023-02-15T08:20:42.301592",
     "exception": false,
     "start_time": "2023-02-15T08:20:42.281705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataWrapper(Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.data = torch.from_numpy(data).long() #преобразуем в целочисленный тензор\n",
    "        self.target = torch.from_numpy(target).long() #преобразуем в целочисленный тензор\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]  #индексация данных\n",
    "        y = self.target[index]  #индексация целевой переменной\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "            \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5fa90cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:42.323856Z",
     "iopub.status.busy": "2023-02-15T08:20:42.323061Z",
     "iopub.status.idle": "2023-02-15T08:20:42.352697Z",
     "shell.execute_reply": "2023-02-15T08:20:42.351853Z"
    },
    "papermill": {
     "duration": 0.042945,
     "end_time": "2023-02-15T08:20:42.354797",
     "exception": false,
     "start_time": "2023-02-15T08:20:42.311852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = DataWrapper(x_train, df_train['label'].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_dataset = DataWrapper(x_valid, df_valid['label'].values)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d2afe",
   "metadata": {
    "papermill": {
     "duration": 0.010295,
     "end_time": "2023-02-15T08:20:42.375472",
     "exception": false,
     "start_time": "2023-02-15T08:20:42.365177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Построение и обучение нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0fa1731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:42.397866Z",
     "iopub.status.busy": "2023-02-15T08:20:42.397012Z",
     "iopub.status.idle": "2023-02-15T08:20:42.405738Z",
     "shell.execute_reply": "2023-02-15T08:20:42.404903Z"
    },
    "papermill": {
     "duration": 0.021805,
     "end_time": "2023-02-15T08:20:42.407684",
     "exception": false,
     "start_time": "2023-02-15T08:20:42.385879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GRUFixedLen(nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, use_last=True):\n",
    "        super().__init__()\n",
    "        self.use_last = use_last\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        gru_out, ht = self.gru(x)\n",
    "       \n",
    "        if self.use_last:\n",
    "            last_tensor = gru_out[:,-1,:]\n",
    "        else:\n",
    "            # use mean\n",
    "            last_tensor = torch.mean(gru_out[:,:], dim=1)\n",
    "    \n",
    "        out = self.linear(last_tensor)\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94ffe6d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:42.430047Z",
     "iopub.status.busy": "2023-02-15T08:20:42.429310Z",
     "iopub.status.idle": "2023-02-15T08:20:42.435685Z",
     "shell.execute_reply": "2023-02-15T08:20:42.434751Z"
    },
    "papermill": {
     "duration": 0.019615,
     "end_time": "2023-02-15T08:20:42.437644",
     "exception": false,
     "start_time": "2023-02-15T08:20:42.418029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edb8f4cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:42.460277Z",
     "iopub.status.busy": "2023-02-15T08:20:42.459527Z",
     "iopub.status.idle": "2023-02-15T08:20:46.936584Z",
     "shell.execute_reply": "2023-02-15T08:20:46.935554Z"
    },
    "papermill": {
     "duration": 4.491894,
     "end_time": "2023-02-15T08:20:46.939856",
     "exception": false,
     "start_time": "2023-02-15T08:20:42.447962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GRUFixedLen(max_words).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c79e150",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T08:20:46.974972Z",
     "iopub.status.busy": "2023-02-15T08:20:46.974630Z",
     "iopub.status.idle": "2023-02-15T08:21:07.788168Z",
     "shell.execute_reply": "2023-02-15T08:21:07.785943Z"
    },
    "papermill": {
     "duration": 20.833999,
     "end_time": "2023-02-15T08:21:07.791005",
     "exception": false,
     "start_time": "2023-02-15T08:20:46.957006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]. Step [47/47]. Loss: 0.200. Acc: 0.931. Test loss: 0.502. Test acc: 0.937\n",
      "Epoch [2/10]. Step [47/47]. Loss: 0.175. Acc: 0.941. Test loss: 0.029. Test acc: 0.943\n",
      "Epoch [3/10]. Step [47/47]. Loss: 0.103. Acc: 0.949. Test loss: 0.030. Test acc: 0.952\n",
      "Epoch [4/10]. Step [47/47]. Loss: 0.133. Acc: 0.959. Test loss: 0.020. Test acc: 0.956\n",
      "Epoch [5/10]. Step [47/47]. Loss: 0.107. Acc: 0.964. Test loss: 0.007. Test acc: 0.957\n",
      "Epoch [6/10]. Step [47/47]. Loss: 0.047. Acc: 0.972. Test loss: 0.009. Test acc: 0.957\n",
      "Epoch [7/10]. Step [47/47]. Loss: 0.071. Acc: 0.978. Test loss: 0.315. Test acc: 0.956\n",
      "Epoch [8/10]. Step [47/47]. Loss: 0.033. Acc: 0.981. Test loss: 0.001. Test acc: 0.953\n",
      "Epoch [9/10]. Step [47/47]. Loss: 0.035. Acc: 0.984. Test loss: 0.050. Test acc: 0.955\n",
      "Epoch [10/10]. Step [47/47]. Loss: 0.056. Acc: 0.987. Test loss: 0.013. Test acc: 0.952\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "th = 0.5\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    model.train() \n",
    "    running_items, running_right = 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # подсчет ошибки на обучении\n",
    "        loss = loss.item()\n",
    "        running_items += len(labels)\n",
    "        # подсчет метрики на обучении\n",
    "        pred_labels = torch.squeeze((outputs > th).int())\n",
    "        running_right += (labels == pred_labels).sum()\n",
    "        \n",
    "    # выводим статистику о процессе обучения\n",
    "    model.eval()\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
    "          f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "          f'Loss: {loss:.3f}. ' \\\n",
    "          f'Acc: {running_right / running_items:.3f}', end='. ')\n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    train_loss_history.append(loss)\n",
    "\n",
    "    # выводим статистику на тестовых данных\n",
    "    test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
    "    for j, data in enumerate(valid_loader):\n",
    "        test_labels = data[1].to(device)\n",
    "        test_outputs = model(data[0].to(device))\n",
    "        \n",
    "        # подсчет ошибки на тесте\n",
    "        test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
    "        # подсчет метрики на тесте\n",
    "        test_running_total += len(data[1])\n",
    "        pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
    "        test_running_right += (test_labels == pred_test_labels).sum()\n",
    "    \n",
    "    test_loss_history.append(test_loss.item())\n",
    "    print(f'Test loss: {test_loss:.3f}. Test acc: {test_running_right / test_running_total:.3f}')\n",
    "            \n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e5026",
   "metadata": {
    "papermill": {
     "duration": 0.011482,
     "end_time": "2023-02-15T08:21:07.815011",
     "exception": false,
     "start_time": "2023-02-15T08:21:07.803529",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Вывод:\n",
    "\n",
    "#### Точность модели на основе GRU сети с первого раза получилась довольно хорошей. Видно, что переобучение отсутствует."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 87.536071,
   "end_time": "2023-02-15T08:21:10.297426",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-15T08:19:42.761355",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
