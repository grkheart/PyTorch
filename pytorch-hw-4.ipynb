{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96abc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35f441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOwnCifar(torch.utils.data.Dataset):\n",
    "    def __init__(self, init_dataset, transform=None):\n",
    "        self._base_dataset = init_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self._base_dataset[idx][0]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, self._base_dataset[idx][1]\n",
    "\n",
    "def train_valid_split(Xt):\n",
    "    X_train, X_test = train_test_split(Xt, test_size=0.05, random_state=13)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecff760",
   "metadata": {},
   "source": [
    "### Задание 1. Обучите CNN (самописная) на CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd8acdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.CIFAR100(root='data/', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b0c08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n",
      "\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "classes = dataset.classes\n",
    "print(classes)\n",
    "print()\n",
    "print(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59fcd348",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_actions = transforms.Compose([transforms.Resize(44),\n",
    "                                    transforms.RandomCrop(32, padding=4),\n",
    "                                    transforms.ToTensor()])\n",
    "\n",
    "train_dataset, valid_dataset = train_valid_split(dataset)\n",
    "\n",
    "train_dataset = MyOwnCifar(train_dataset, trans_actions)\n",
    "\n",
    "valid_dataset = MyOwnCifar(valid_dataset, transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=128,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                           batch_size=128,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3574a627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32])\n",
      "bus\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for img, lbl in train_loader:\n",
    "    print(img.shape)\n",
    "    print(classes[lbl[0]])\n",
    "    plt.imshow(img[0].permute(1, 2, 0))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe56930b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (dp_three): Dropout(p=0.1, inplace=False)\n",
      "  (dp_four): Dropout(p=0.2, inplace=False)\n",
      "  (bn_one): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_one): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn_two): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_two): Conv2d(30, 60, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn_three): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_three): Conv2d(60, 120, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn_four): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=2160, out_features=1080, bias=True)\n",
      "  (fc2): Linear(in_features=1080, out_features=540, bias=True)\n",
      "  (out): Linear(in_features=540, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.dp_three = nn.Dropout(0.1)\n",
    "        self.dp_four = nn.Dropout(0.2)\n",
    "        self.bn_one = torch.nn.BatchNorm2d(3)\n",
    "        self.conv_one = torch.nn.Conv2d(3, 30, 3)\n",
    "        self.bn_two = torch.nn.BatchNorm2d(30)\n",
    "        self.conv_two = torch.nn.Conv2d(30, 60, 3)\n",
    "        self.bn_three = torch.nn.BatchNorm2d(60)\n",
    "        self.conv_three = torch.nn.Conv2d(60, 120, 3)\n",
    "        self.bn_four = torch.nn.BatchNorm2d(120)\n",
    "        self.fc1 = torch.nn.Linear(2160, 1080)\n",
    "        self.fc2 = torch.nn.Linear(1080, 540)\n",
    "        self.out = torch.nn.Linear(540, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn_one(x)\n",
    "        x = self.conv_one(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.bn_two(x)\n",
    "        x = self.conv_two(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.bn_three(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dp_three(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp_four(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return self.out(x)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d1df3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d5e0222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1            [-1, 3, 32, 32]               6\n",
      "            Conv2d-2           [-1, 30, 30, 30]             840\n",
      "       BatchNorm2d-3           [-1, 30, 15, 15]              60\n",
      "            Conv2d-4           [-1, 60, 13, 13]          16,260\n",
      "       BatchNorm2d-5             [-1, 60, 6, 6]             120\n",
      "           Dropout-6                 [-1, 2160]               0\n",
      "            Linear-7                 [-1, 1080]       2,333,880\n",
      "           Dropout-8                 [-1, 1080]               0\n",
      "            Linear-9                  [-1, 540]         583,740\n",
      "           Linear-10                  [-1, 100]          54,100\n",
      "================================================================\n",
      "Total params: 2,989,006\n",
      "Trainable params: 2,989,006\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.41\n",
      "Params size (MB): 11.40\n",
      "Estimated Total Size (MB): 11.83\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd981700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]. Step [1/371]. Loss: 0.036. Acc: 0.008. Test acc: 0.006\n",
      "Epoch [1/5]. Step [301/371]. Loss: 0.034. Acc: 0.039. Test acc: 0.067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▊                                                                   | 1/5 [00:29<01:56, 29.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5]. Step [1/371]. Loss: 2.387. Acc: 0.023. Test acc: 0.032\n",
      "Epoch [2/5]. Step [301/371]. Loss: 0.037. Acc: 0.010. Test acc: 0.008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:59<01:28, 29.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5]. Step [1/371]. Loss: 70.983. Acc: 0.008. Test acc: 0.007\n",
      "Epoch [3/5]. Step [301/371]. Loss: 0.037. Acc: 0.009. Test acc: 0.007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [01:29<01:00, 30.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5]. Step [1/371]. Loss: 2.152. Acc: 0.008. Test acc: 0.010\n",
      "Epoch [4/5]. Step [301/371]. Loss: 0.036. Acc: 0.010. Test acc: 0.009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [02:00<00:30, 30.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]. Step [1/371]. Loss: 0.188. Acc: 0.016. Test acc: 0.011\n",
      "Epoch [5/5]. Step [301/371]. Loss: 0.036. Acc: 0.009. Test acc: 0.010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:34<00:00, 30.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    net.train()\n",
    "    \n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0], data[1]\n",
    "\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # выводим статистику о процессе обучения\n",
    "        running_loss += loss.item()\n",
    "        running_items += len(labels)\n",
    "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
    "        \n",
    "        # выводим статистику о процессе обучения\n",
    "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
    "            net.eval()\n",
    "            \n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
    "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
    "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
    "            \n",
    "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "\n",
    "            test_running_right, test_running_total = 0.0, 0.0\n",
    "            \n",
    "            for i, data in enumerate(valid_loader):\n",
    "                test_outputs = net(data[0])\n",
    "                test_running_total += len(data[1])\n",
    "                test_running_right += (data[1] == torch.max(test_outputs, 1)[1]).sum()\n",
    "            \n",
    "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
    "        \n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44d76b5",
   "metadata": {},
   "source": [
    "### Задание 2. Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e099180",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = resnet50(weights=ResNet50_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87633633",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(256),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                normalize,\n",
    "                                transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7890ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.set_parameter_requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b2fc6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_parameter_requires_grad(resnet50, True)\n",
    "resnet50.fc = nn.Linear(2048, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e8fa79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_actions = transforms.Compose([transforms.Resize(256),\n",
    "                                    transforms.RandomCrop(224, padding=4),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                         std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "valid_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                            std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "train_dataset, valid_dataset = train_valid_split(dataset)\n",
    "\n",
    "train_dataset = MyOwnCifar(train_dataset, trans_actions)\n",
    "\n",
    "valid_dataset = MyOwnCifar(valid_dataset, valid_transforms)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=128,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                           batch_size=128,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68fdd12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = []\n",
    "\n",
    "for name, param in resnet50.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7826b038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
      "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
      "             ReLU-15            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
      "           Conv2d-17             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
      "             ReLU-19             [-1, 64, 8, 8]               0\n",
      "           Conv2d-20             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
      "             ReLU-22             [-1, 64, 8, 8]               0\n",
      "           Conv2d-23            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
      "             ReLU-25            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
      "           Conv2d-27             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
      "             ReLU-29             [-1, 64, 8, 8]               0\n",
      "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
      "             ReLU-32             [-1, 64, 8, 8]               0\n",
      "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
      "             ReLU-35            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 128, 8, 8]          32,768\n",
      "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
      "             ReLU-39            [-1, 128, 8, 8]               0\n",
      "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
      "             ReLU-42            [-1, 128, 4, 4]               0\n",
      "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-47            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
      "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
      "             ReLU-51            [-1, 128, 4, 4]               0\n",
      "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
      "             ReLU-54            [-1, 128, 4, 4]               0\n",
      "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-57            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
      "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
      "             ReLU-61            [-1, 128, 4, 4]               0\n",
      "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
      "             ReLU-64            [-1, 128, 4, 4]               0\n",
      "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-67            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
      "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
      "             ReLU-71            [-1, 128, 4, 4]               0\n",
      "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
      "             ReLU-74            [-1, 128, 4, 4]               0\n",
      "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-77            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
      "           Conv2d-79            [-1, 256, 4, 4]         131,072\n",
      "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
      "             ReLU-81            [-1, 256, 4, 4]               0\n",
      "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
      "             ReLU-84            [-1, 256, 2, 2]               0\n",
      "           Conv2d-85           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
      "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-89           [-1, 1024, 2, 2]               0\n",
      "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-91            [-1, 256, 2, 2]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 2, 2]             512\n",
      "             ReLU-93            [-1, 256, 2, 2]               0\n",
      "           Conv2d-94            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
      "             ReLU-96            [-1, 256, 2, 2]               0\n",
      "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-99           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
      "            ReLU-103            [-1, 256, 2, 2]               0\n",
      "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
      "            ReLU-106            [-1, 256, 2, 2]               0\n",
      "          Conv2d-107           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-109           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-111            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
      "            ReLU-113            [-1, 256, 2, 2]               0\n",
      "          Conv2d-114            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 2, 2]             512\n",
      "            ReLU-116            [-1, 256, 2, 2]               0\n",
      "          Conv2d-117           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-119           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-121            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
      "            ReLU-123            [-1, 256, 2, 2]               0\n",
      "          Conv2d-124            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
      "            ReLU-126            [-1, 256, 2, 2]               0\n",
      "          Conv2d-127           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-129           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
      "            ReLU-133            [-1, 256, 2, 2]               0\n",
      "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
      "            ReLU-136            [-1, 256, 2, 2]               0\n",
      "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-139           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-143            [-1, 512, 2, 2]               0\n",
      "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-146            [-1, 512, 1, 1]               0\n",
      "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
      "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-151           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-155            [-1, 512, 1, 1]               0\n",
      "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-158            [-1, 512, 1, 1]               0\n",
      "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-161           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-165            [-1, 512, 1, 1]               0\n",
      "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-168            [-1, 512, 1, 1]               0\n",
      "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-171           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                  [-1, 100]         204,900\n",
      "================================================================\n",
      "Total params: 23,712,932\n",
      "Trainable params: 23,712,932\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.86\n",
      "Params size (MB): 90.46\n",
      "Estimated Total Size (MB): 96.33\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(resnet50, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671dd0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]. Step [1/371]. Loss: 0.036. Acc: 0.000. Test acc: 0.009\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    resnet50.train()\n",
    "    \n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0], data[1]\n",
    "\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = resnet50(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # выводим статистику о процессе обучения\n",
    "        running_loss += loss.item()\n",
    "        running_items += len(labels)\n",
    "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
    "        \n",
    "        # выводим статистику о процессе обучения\n",
    "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
    "            resnet50.eval()\n",
    "            \n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
    "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
    "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
    "            \n",
    "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "\n",
    "            test_running_right, test_running_total = 0.0, 0.0\n",
    "            \n",
    "            for i, data in enumerate(valid_loader):\n",
    "                test_outputs = resnet50(data[0])\n",
    "                test_running_total += len(data[1])\n",
    "                test_running_right += (data[1] == torch.max(test_outputs, 1)[1]).sum()\n",
    "            \n",
    "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
    "        \n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23799b9",
   "metadata": {},
   "source": [
    "### Задание 3. Сравните результаты обучения на эквивалентном числе эпох"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ac9741",
   "metadata": {},
   "source": [
    "С resnet50 не прогружается дальше первой строчки даже в colab с cuda. Но видно, что accuracy на тесте сразу чуть выше. Вероятно, с resnet50 loss должна быть ниже, а точность выше на эквивалентном числе эпох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39789c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
