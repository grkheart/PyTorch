{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PT_hw_9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Урок 9. Трансформер"
      ],
      "metadata": {
        "id": "LO9XEqIPVQNw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Домашнее задание"
      ],
      "metadata": {
        "id": "gCm3MDF6VlPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Возьмите готовую модель из https://huggingface.co/models для классификации сентимента текста.\n",
        "2. Сделайте предсказания на всем df_val. Посчитайте метрику качества.\n",
        "3. Дообучите эту модель на df_train. Посчитайте метрику качества на df_val.<br>\n",
        "   Данные на google drive: https://drive.google.com/file/d/1Mev_EEput0LlBj8MDHIJkBtahlJ6J901"
      ],
      "metadata": {
        "id": "bdf78yokVohc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подключение библиотек"
      ],
      "metadata": {
        "id": "KgMD_AldVxuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sagT1UAWUAm",
        "outputId": "59618058-d0e5-4473-8c14-4630a25223c7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_rcLx4QzqyY",
        "outputId": "b3ab5977-46ca-4766-afc3-1910bd22723c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.2.0)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.11.0+cu113)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import Adam\n",
        "\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torchmetrics import F1Score"
      ],
      "metadata": {
        "id": "7pFwneHJV8Fr"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gIdO3XW084xp",
        "outputId": "96afe1e8-b96c-43ed-fe0c-0a535e1a5a82"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка данных"
      ],
      "metadata": {
        "id": "4oWbwl38XWrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"/content/drive/MyDrive/data/train.csv\")\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/data/val.csv\")\n",
        "\n",
        "df_train.shape, df_val.shape"
      ],
      "metadata": {
        "id": "5Q3zvjtzXWA1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6517edc9-9a70-49a3-e4e4-58447e867278"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((181467, 3), (22683, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "RH7B5Ku3YEkC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "61b4bc3d-c976-4cb4-fc2c-caf88a868c75"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                               text  class\n",
              "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
              "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
              "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
              "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
              "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc00923a-35e0-474e-b00a-300cd9d1be21\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc00923a-35e0-474e-b00a-300cd9d1be21')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc00923a-35e0-474e-b00a-300cd9d1be21 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc00923a-35e0-474e-b00a-300cd9d1be21');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка и проверка работы модели"
      ],
      "metadata": {
        "id": "feOeoTYjCijO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выбрана модель cointegrated/rubert-tiny-toxicity"
      ],
      "metadata": {
        "id": "BL-s6CxsCtvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/cointegrated/rubert-tiny-toxicity"
      ],
      "metadata": {
        "id": "f2qda1o2Cy4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('cointegrated/rubert-tiny-toxicity')\n",
        "model = BertForSequenceClassification.from_pretrained('cointegrated/rubert-tiny-toxicity')"
      ],
      "metadata": {
        "id": "ee7tWmWxYnas"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка работы модели\n",
        "sentiment = pipeline(\"text-classification\", model='cointegrated/rubert-tiny-toxicity')\n",
        "sentiment(\"Хорошая погода\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYtXoBwGY5n7",
        "outputId": "f137d1cf-44b0-4eaf-a36a-b66ec74fe700"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'non-toxic', 'score': 0.9994722008705139}]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Проверка работы токенайзера\n",
        "\n",
        "example_text = 'Пример текста для токенизации'\n",
        "bert_input = tokenizer(example_text, padding='max_length', max_length=15, \n",
        "                       truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "print(bert_input['input_ids'])\n",
        "print(bert_input['attention_mask'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UJQEfdaDgSr",
        "outputId": "3072c4d3-433a-4bb4-afc3-1a80999aaa2b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    2,  3086, 10885, 22723,   871, 24302,  3464, 10880,     3,     0,\n",
            "             0,     0,     0,     0,     0]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка параметров модели\n",
        "print(model)\n",
        "print(\"Parameters full train:\", sum([param.nelement() for param in model.parameters()]))"
      ],
      "metadata": {
        "id": "UKOm2YkcZEHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a0bafd7-78b1-4bce-cf6e-8137040cba59"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertForSequenceClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(29564, 312, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 312)\n",
            "      (token_type_embeddings): Embedding(2, 312)\n",
            "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
            "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
            "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
            "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
            "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
            "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
            "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
            "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
            "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
            "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
            "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
            "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
            "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=312, out_features=5, bias=True)\n",
            ")\n",
            "Parameters full train: 11785733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка данных"
      ],
      "metadata": {
        "id": "tF2OVS_zGROK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 20\n",
        "print(df_train.iloc[idx]['text'])\n",
        "print('label is', df_train.iloc[idx]['class'])\n",
        "sentiment(df_train.iloc[idx]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DuuuN7CGYBu",
        "outputId": "d810d656-e87f-4903-ae5c-4ef85f06e646"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Австрия ждеееет! Последние формальности уладили) Буду сегодня паковать чемодан!))\n",
            "label is 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'non-toxic', 'score': 0.9992603659629822}]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['text'] = df_train['text'].apply(lambda x: x.lower())\n",
        "df_val['text'] = df_val['text'].apply(lambda x: x.lower())"
      ],
      "metadata": {
        "id": "gPyqIooIYGYW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset"
      ],
      "metadata": {
        "id": "4QPfB8ytHPpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TwitterDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, txts, labels):\n",
        "        self._labels = labels\n",
        "        \n",
        "        self.tokenizer = BertTokenizer.from_pretrained('cointegrated/rubert-tiny-toxicity')\n",
        "        self._txts = [self.tokenizer(text, padding='max_length', max_length=10,\n",
        "                                     truncation=True, return_tensors=\"pt\")\n",
        "                      for text in txts]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self._txts)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self._txts[index], self._labels[index]"
      ],
      "metadata": {
        "id": "ZHkUEC9qHINM"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoader"
      ],
      "metadata": {
        "id": "Oo6fECiEHWNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = df_train['class']\n",
        "y_val = df_val['class']\n",
        "\n",
        "train_dataset = TwitterDataset(df_train['text'], y_train)\n",
        "valid_dataset = TwitterDataset(df_val['text'], y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=True,\n",
        "                          num_workers=0)\n",
        "valid_loader = DataLoader(valid_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=False,\n",
        "                          num_workers=0)"
      ],
      "metadata": {
        "id": "3TSr6BCcHZVd"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for txt, lbl in train_loader:\n",
        "    print(txt.keys())\n",
        "    print(txt['input_ids'].shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBiJ5NXqIpjN",
        "outputId": "657c3bf9-8cd3-4cad-a42e-be090c5cdda0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
            "torch.Size([128, 1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Построение и обучение нейронной сети"
      ],
      "metadata": {
        "id": "n-phM-pN1gBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.pretrained_model = BertForSequenceClassification.from_pretrained('cointegrated/rubert-tiny-toxicity')\n",
        "        self.sigm = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        pooled_output = self.pretrained_model(input_ids=x, attention_mask=mask,return_dict=False)[0]\n",
        "        final = self.sigm(pooled_output)\n",
        "        return final"
      ],
      "metadata": {
        "id": "63X9copD1noq"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertClassifier().to(device)"
      ],
      "metadata": {
        "id": "CP_6riXY97VW"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.pretrained_model.classifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FihkYb2BJP-O",
        "outputId": "7414afdf-ad17-4317-bfb7-4eaeb48d8d40"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=312, out_features=5, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.pretrained_model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "7ljL9vLY-aI_"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_f1 = F1Score().to(device)\n",
        "valid_f1 = F1Score().to(device)\n",
        "\n",
        "for epoch_num in range(10):\n",
        "    total_acc_train = 0\n",
        "    total_loss_train = 0\n",
        "\n",
        "    model.train()\n",
        "    for train_input, train_label in tqdm(train_loader):\n",
        "        mask = train_input['attention_mask'].to(device)\n",
        "        input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "        train_label = train_label.to(device)\n",
        "        \n",
        "        output = model(input_id, mask)\n",
        "\n",
        "        batch_loss = criterion(output, train_label)\n",
        "        total_loss_train += batch_loss.item()\n",
        "\n",
        "        train_f1(output, train_label)\n",
        "\n",
        "        acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "        total_acc_train += acc\n",
        "\n",
        "        model.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "            \n",
        "    model.eval()\n",
        "    total_loss_val, total_acc_val = 0.0, 0.0\n",
        "    for val_input, val_label in valid_loader:\n",
        "        val_label = val_label.to(device)\n",
        "        mask = val_input['attention_mask'].to(device)\n",
        "        input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "        output = model(input_id, mask)\n",
        "\n",
        "        batch_loss = criterion(output, val_label)\n",
        "        total_loss_val += batch_loss.item()\n",
        "                    \n",
        "        acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "        total_acc_val += acc\n",
        "\n",
        "        valid_f1(output, val_label)\n",
        "\n",
        "      \n",
        "    print(\n",
        "        f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_dataset): .3f} \\\n",
        "        | Train Accuracy: {total_acc_train / len(train_dataset): .3f} \\\n",
        "        | Train f1: {train_f1.compute().item(): .3f} \\\n",
        "        | Val Loss: {total_loss_val / len(valid_dataset): .3f} \\\n",
        "        | Val Accuracy: {total_acc_val / len(valid_dataset): .3f} \\\n",
        "        | Val f1: {valid_f1.compute().item(): .3f}')\n",
        "    \n",
        "    train_f1.reset()\n",
        "    valid_f1.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrtkxFRb-zgD",
        "outputId": "e0d185b9-3b9f-41d2-d099-d8e8d02dd798"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1418/1418 [00:29<00:00, 48.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  0.009         | Train Accuracy:  0.494         | Train f1:  0.494         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1418/1418 [00:26<00:00, 54.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  0.009         | Train Accuracy:  0.494         | Train f1:  0.494         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1418/1418 [00:25<00:00, 54.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  0.009         | Train Accuracy:  0.493         | Train f1:  0.493         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1418/1418 [00:25<00:00, 54.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss:  0.009         | Train Accuracy:  0.493         | Train f1:  0.493         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1418/1418 [00:26<00:00, 54.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss:  0.009         | Train Accuracy:  0.493         | Train f1:  0.493         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1418/1418 [00:25<00:00, 54.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 6 | Train Loss:  0.009         | Train Accuracy:  0.493         | Train f1:  0.493         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1418/1418 [00:26<00:00, 53.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 7 | Train Loss:  0.009         | Train Accuracy:  0.493         | Train f1:  0.493         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1418/1418 [00:25<00:00, 54.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 8 | Train Loss:  0.009         | Train Accuracy:  0.493         | Train f1:  0.493         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1418/1418 [00:25<00:00, 54.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 9 | Train Loss:  0.009         | Train Accuracy:  0.493         | Train f1:  0.493         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1418/1418 [00:25<00:00, 54.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 10 | Train Loss:  0.009         | Train Accuracy:  0.493         | Train f1:  0.493         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495\n"
          ]
        }
      ]
    }
  ]
}